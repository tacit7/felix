# TripAdvisor Scraper Suite

Universal scraping system for TripAdvisor restaurants and attractions data, built using advanced GraphQL techniques.

## Source & Attribution

**Built using techniques from:** https://scrapfly.io/blog/posts/how-to-scrape-tripadvisor

This scraper implements the advanced GraphQL bypassing methods detailed in the Scrapfly article, including:
- GraphQL query ID discovery via Chrome Developer Console
- Proper anti-bot headers with X-Requested-By random strings
- HTTP/2 connections for authenticity
- Rate limiting and request rotation strategies

## Files Overview

### Core Scrapers
- **`universal_city_scraper.py`** - Main scraper for any city worldwide
- **`scraper_runner.py`** - Quick command-line interface
- **`isla_verde_restaurants_scraper.py`** - Original Isla Verde implementation
- **`final_isla_verde_scraper.py`** - Original attractions scraper

### Documentation & Debugging
- **`TRIPADVISOR_SCRAPING_GUIDE.md`** - Complete guide for finding GraphQL query IDs
- **`debug_restaurant_search.py`** - Debug script for testing location types

### Phoenix Integration
- **`../lib/tasks/auto_scrape_places.ex`** - Phoenix Mix task for database integration

## Quick Usage

### Command Line Scraping
```bash
# Any city worldwide
python3 scraper_runner.py "Austin, TX" --quick
python3 scraper_runner.py "Miami, FL" --restaurants-only  
python3 universal_city_scraper.py "Tokyo, Japan"

# Full comprehensive scraping
python3 universal_city_scraper.py "New York" --type all
```

### Phoenix Backend Integration
```bash
# Scrape specific city and import to database
mix auto_scrape_places "Dallas, TX"

# Check all cities and auto-scrape those needing data
mix auto_scrape_places --check-all --min-places 15

# Dry run to see what would be scraped
mix auto_scrape_places --check-all --dry-run
```

## Key Features

‚úÖ **Universal**: Works for any city worldwide  
‚úÖ **Anti-Bot Protection**: Bypasses TripAdvisor's blocking  
‚úÖ **GraphQL Based**: Uses working query ID `c2e5695e939386e4`  
‚úÖ **Database Integration**: Direct import to Phoenix Places table  
‚úÖ **Deduplication**: Removes duplicate results by URL  
‚úÖ **Rate Limited**: Respectful 2.5s delays between requests  
‚úÖ **Error Handling**: Graceful failure handling and retries  

## Technical Implementation

- **Query ID**: `c2e5695e939386e4` (universal working ID)
- **Location Types**: `["EATERY"]` for restaurants, `["ATTRACTION"]` for attractions
- **Headers**: Proper anti-bot headers including random X-Requested-By strings
- **Rate Limiting**: 2.5 second delays between requests
- **Deduplication**: By TripAdvisor URL to avoid duplicates

## Success Metrics

Our implementation successfully:
- ‚úÖ Bypassed 403 errors using proper headers
- ‚úÖ Found 30+ attractions per city with real TripAdvisor URLs  
- ‚úÖ Found 18+ restaurants per city with location IDs
- ‚úÖ Extracted coordinates and address data
- ‚úÖ Rate limited properly to avoid blocking
- ‚úÖ Integrated with Phoenix backend for automatic database import

## Legal & Ethical Usage

- ‚úÖ Respects robots.txt and rate limits
- ‚úÖ Only collects public business information
- ‚úÖ Uses data for legitimate travel application purposes  
- ‚úÖ Caches results to minimize requests
- ‚ùå Does not collect personal data or reviews
- ‚ùå Avoids excessive scraping that impacts site performance

---

**This scraping system provides reliable TripAdvisor data collection while respecting the platform's terms and implementing proper anti-detection measures.** üéØ